---
output:
  pdf_document: default
  html_document: default
---
# Empirical results 

```{r, echo = FALSE, warning=FALSE,message=FALSE}
rm(list = ls())
library(deepvars)
library(data.table)
```

```{r, echo = FALSE, warning=FALSE,message=FALSE}
dt_all <- readRDS("data_VAR/preprocessed.rds")
var_cols <- colnames(dt_all)[2:ncol(dt_all)]
```

```{r}
# Choosing lags
lags <- lag_order(dt_all, max_lag = 12)$p
```

```{r, echo = FALSE, warning=FALSE,message=FALSE,eval=TRUE}
# VAR fitting
var_model <- vareg(dt_all, lags = lags)
saveRDS(var_model, file="results/var_model_full_sample.rds")
# Deep VAR fitting
deepvar_model <- deepvareg(dt_all, lags=lags, num_units = 100, epochs=100, p_drop_out = 0.5)
saveRDS(deepvar_model, file="results/deepvar_model_full_sample.rds")
```

```{r, eval=FALSE}
var_model <- readRDS("results/var_model_full_sample.rds")
deepvar_model <- readRDS("results/deepvar_model_full_sample.rds")
```


```{r}
# Cum RMSE plot
cum_loss_var <- cum_loss(var_model)$cum_loss[,type:="var"]
cum_loss_dvar <- cum_loss(deepvar_model)$cum_loss[,type:="deepvar"]
dt_plot <- rbind(cum_loss_dvar, cum_loss_var)
ggplot2::ggplot(data=dt_plot, ggplot2::aes(x=date, y=value, colour=type)) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~variable, scales = "free_y") +
  ggplot2::scale_color_discrete(name="Model:") +
  ggplot2::labs(
      x="Date",
      y="Squared error"
    )
```


In this section we present the main empirical results. First of all, we compare the in-sample fit of the VAR and the Deep-VAR. Then, we proceed with the out-of-sample predicitions. In both cases we compute the cumulative loss for the two methods. Finally, we use the fitted models to produce forecasts. 

In figure XX we can see the cumulative RMSE of both the VAR model and Deep-VAR model for each of the time series. The first thing we can observe is that the RMSE of the Deep-VAR is consistently flatter than the RMSE of the VAR. Indicating that the the performance of the Deep-VAR model is better than the one of the VAR throughout the time period of the experimental analysis. This simple fact implies that there are non linear relationships present in the time series. Another interesting insight we can derive form the figure is that the RMSE of the Deep-VAR ends up being even less than half of the RMSE of the VAR, clearly indicating that, overall, the Deep-VAR model outperforms the VAR model for the in-sample fit.

Figure XX is especially useful to asses in which specific periods the Deep-VAR model accomplishes much better fitting results than the VAR model. From the very beginning, we can observe that the slope of the VAR model is grater than the one of the Deep-VAR model, indicating that even in normal economic times, soft non linear relationships may be present in the series.

The first change we can observe is in the beginning of the 1980s. During the beginning of this decade, the RMSE of the Deep-VAR almost remains constant (it slope is close to zero), therefore, it almost makes no error. On the other hand, the RMSE of the VAR keeps increasing. For the case of the IP and the UR, the RMSE of the VAR  maintains its previous slope, meaning no improvement nor deterioration appears. Whereas for the CPI, it becomes approximately as twice as big, hence doubling its error, and for the FFR it is approximately quadrupled.

This can be explained by the early 1980s recession. This recession is considered to be the most sever since World War II. As figure XX shows, the Deep-VAR model almost perfectly fits the data in this period. This is due to the fact that economic recessions have a very high component of non linear relationships, therefore not only the Deep-VAR does better than the VAR, but it almost accomplishes a perfect fit. This idea is then reinforced by the poor performance of the VAR in this period for the CPI and FFR series. Both series, specially the FFR, are very volatile in this period. This means that non linear relationships are present and therefore, the Deep-VAR model remains unaffected by the volatility, while the VAR model struggles a lot to fit the data due to its limitations for fitting data generating processes with non linear components.

For the case of the 2007 recession we can see a pattern similar to the one for the recession of the early 1980: the Deep-VAR achieves a better fit because it can correctly identify the pattern soon enough. Furthermore, in the recovery time, the Deep-VAR cumulative RMSE still has a lower slope than the VAR cumulative RMSE. 

Finally, we can compare how both models perform in a period with highly non linear components, the Covid era. It can be clearly seen that, for both IP and UR, that is, the series that really changed its behavior with Covid, the VAR model struggles a lot to fit the data. For the VAR model, both series add in a few months approximately 50% of the error tehy had been accumulating for the previous 60 years. Whereas in the case of the Deep-VAR model, they only accumulate approximately 30% of the error they had been accumulating before. This, once again, reinforces our hypothesis that the Deep-VAR model structure helps dealing with non linarities on the data generating process and therefore fitting the data better on periods where non-linareities are present, which means that the Deep-VAR model can be extremely useful for recession periods.

## Train-test split

```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Train test split
train_test_split <- split_sample(dt_all)
train_data <- train_test_split$train_data
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Select the number of lags
lags <- lag_order(train_data)$p
```


```{r, echo = FALSE, warning=FALSE,message=FALSE, eval=TRUE}
# VAR
var_model <- vareg(train_data, lags = lags)
saveRDS(var_model, file="results/var_model_train.rds")
# Deep VAR
deepvar_model <- deepvareg(train_data, lags=lags, num_units = 100, epochs=100, p_drop_out = 0.5)
saveRDS(deepvar_model, file="results/deepvar_model_train.rds")
```


```{r, eval=FALSE}
var_model <- readRDS("results/var_model_train.rds")
deepvar_model <- readRDS("results/deepvar_model_train.rds")
```

```{r, echo = FALSE, warning=FALSE,message=FALSE}
y_true <- var_model$y_train
```

Now, we split the data into training data and test data. The model will be fitted in the training dataset and then we assess the performance of the model in the test dataset. This is done in order to see the performace of both models on data which is independent of the data that has been used to fit the model. The training dataset goes from March 1959 to November 2007, whereas the test data goes from December 2007 to March 2021, so we train the model on 80 percent of the data and we test the model on the remaining 20 percent. 

```{r, echo = FALSE, warning=FALSE,message=FALSE, results=FALSE, include = FALSE}
#VAR
pred_var <- predict(var_model)
plot(pred_var, y_true = y_true)
```

```{r, echo = FALSE, warning=FALSE,message=FALSE, results=FALSE, include = FALSE}
#DeepVAR
pred_deepvar <- predict(deepvar_model)
plot(pred_deepvar, y_true = y_true)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE,results=FALSE, include = FALSE}
#Predictions out of sample
X_test <- prepare_test_data(train_test_split, lags=lags)$X_test
y_test <- prepare_test_data(train_test_split, lags=lags)$y_test
```


```{r, echo = FALSE, warning=FALSE,message=FALSE,results=FALSE, include = FALSE}
#VAR
pred_var <- predict(var_model, X=X_test)
plot(pred_var, y_true = y_test)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE,results=FALSE, include = FALSE}
#DeepVAR
pred_dvar <- predict(deepvar_model, X=X_test)
plot(pred_dvar, y_true = y_test)
```


```{r, echo = FALSE, results = FALSE, warning=FALSE,message=FALSE, include = FALSE}
#RMSE 
rmse_var <- rbind(
  rmse(var_model)[,model:="var"][,sample:="train"],
  rmse(var_model, X=X_test, y=y_test)[,model:="var"][,sample:="test"]
)
rmse_dvar <- rbind(
  rmse(deepvar_model)[,model:="deepvar"][,sample:="train"],
  rmse(deepvar_model, X=X_test, y=y_test)[,model:="deepvar"][,sample:="test"]
)
tab_rmse <- rbind(rmse_var, rmse_dvar)
tab_rmse <- data.table::dcast(tab_rmse, sample + variable ~ model, value.var = "value")
tab_rmse[, ratio:= deepvar/var]
knitr::kable(tab_rmse, 
  col.names = c("Sample", "Variable", "DVAR", "VAR", "Ratio"),
  digits = 5) 
```

The following table shows ths Root Mean Squared Error (RMSE) for the in-sample and the out-of-sample predictions of both the VAR model and the Deep-VAR model. We can see that the RMSE for the Deep VAR outperforms the one for the classic VAR for both the training data and the test data and for all time series. The fifth column of the table shows us the ratio between the Deep-VAR and the VAR. The lower the ratio, the better the Deep-VAR with respect to the VAR. Note that for the industrial production and for the unemployment rate the Deep-VAR does fairly well compared to the VAR.

```{r, echo = FALSE, results='asis', warning=FALSE,message=FALSE}
library(xtable)
dtf<- xtable(tab_rmse[, -"Mean"], caption = c("RMS"))
names(dtf) <- c('Sample','Variable', 'DeepVAR', "VAR", "Ratio")
bold <- function(x){
paste('{\\textbf{',x,'}}', sep ='')
}
italic <- function(x){
paste0('{\\emph{ ', x, '}}')
}
print(dtf, sanitize.colnames.function = bold, sanitize.rownames.function = italic, booktabs = TRUE, include.rownames=FALSE)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Cumulative loss in-sample

cum_loss_var <- cum_loss(var_model)$cum_loss[,type:="var"]
cum_loss_dvar <- cum_loss(deepvar_model)$cum_loss[,type:="deepvar"]
dt_plot <- rbind(cum_loss_dvar, cum_loss_var)
ggplot2::ggplot(data=dt_plot, ggplot2::aes(x=date, y=value, colour=type)) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~variable, scales = "free_y") +
  ggplot2::scale_color_discrete(name="Model:") +
  ggplot2::labs(
      x="Date",
      y="Squared error"
    )
```



```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Cumulative loss out-of-sample
cum_loss_var <- cum_loss(var_model)$cum_loss[,type:="var"]
cum_loss_dvar <- cum_loss(deepvar_model)$cum_loss[,type:="deepvar"]
dt_plot <- rbind(cum_loss_dvar, cum_loss_var)
ggplot2::ggplot(data=dt_plot, ggplot2::aes(x=date, y=value, colour=type)) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~variable, scales = "free_y") +
  ggplot2::scale_color_discrete(name="Model:") +
  ggplot2::labs(
      x="Date",
      y="Squared error"
    )
```

```{r}
n_ahead <- 12
y_true <- y_test[1:n_ahead,]
```

In the following, we will compare the forecast performance of the VAR and the Deep-VAR. To do that, we compute the 1-step ahead forecast for one year. The dashed line represents the forecast and the solid black line represents the actual value of the time series. To compare the performance of both methods, we compute the Forecast RMSE.
```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Forecasts
#VAR
fcst_var <- forecast(var_model, n.ahead = n_ahead)
plot(fcst_var, y_true=y_true, history = 20)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#DeepVAR
fcst_dvar <- forecast(deepvar_model, n.ahead = n_ahead)
plot(fcst_dvar, y_true=y_true, history = 20)
```


In the following table, we look more specifically at this comparison. In particular, we compute the Forecast RMSE for the VAR method and for the Deep-VAR, and we also compute the correlation of the forecast with the actual value of each time series.

```{r, echo = FALSE, warning=FALSE,message=FALSE, include= FALSE}
rmsfe(fcst_dvar, y_true = y_true)
rmsfe(fcst_var, y_true = y_true)
correlations <- function(fcst_var,fcst_dvar,y_true){
  list_names <- c(colnames(y_true))
  cor_var <- c()
  cor_dvar <- c()
  for (n in list_names){
    cor_var <- c(cor_var,cor(fcst_var$fcst[, ..n][-1], y_true[,n]))
    cor_dvar <- c(cor_dvar,cor(fcst_dvar$fcst[, ..n][-1], y_true[,n]))
    
  }
  return(data.table(cor_var,cor_dvar))
}
correlations <- correlations(fcst_var,fcst_dvar,y_true)
```

```{r, results = 'asis', echo = FALSE, warning=FALSE,message=FALSE}
tab_fcst <- data.table("Variable" = colnames(y_true), "VAR FRMSE"= rmsfe(fcst_var, y_true = y_true)[,value] , "Deep-VAR FRMSE"= rmsfe(fcst_dvar, y_true = y_true)[,value],
                       "VAR correlations" =correlations$cor_var ,
                       "Deep-VAR correlations" = correlations$cor_dvar)
dtf<- xtable(tab_fcst, caption = c("Forecasts results"))
print(dtf, sanitize.colnames.function = bold, sanitize.rownames.function = italic, booktabs = TRUE, include.rownames=FALSE,size = "\\setlength{\\tabcolsep}{2pt}")
```

As we can see in the table, the Forecast RMSE of the Deep-VAR is lower than the one for the VAR for unemployment rate and for the federal funds rate, and it is the same for industrial production and inflation. Hence, the Deep-VAR outperforms the VAR in terms of forecasts. It is also of interest to analyze the correlation between the forecasts and the actual values. In the case of the VAR, there is, for all time series, a negative correlation, that is, when the time series evolves in one direction, the VAR forecast evolves in the opposite direction. However, this is not true for the Deep-VAR. For industrial production, is certainly true that the Deep-VAR forecast has a highly negative correlation with the actual values, but achives the same forecasting performance than the one for the VAR. However, for the rest of time series, the Deep-VAR has a positive correlation, that is, the forecast generally evolves in the same direction as the actuial values. Note that this positive correlation cannot be too strong given that the forecasts at some point in time return to the mean, and hence, have no varaiability.  

## Grid search

```{r, include= FALSE, eval=FALSE, echo = FALSE}
# Parameters
n_ahead <- 12
layers <- c(1,2,5)
units <- c(50,100,150)
dropout <- c(0.3,0.5,0.7)
lags <- c(10,50,100)
grid <- data.table::CJ(
  layer = layers,
  unit = units,
  dropout = dropout
)
n_sim <- length(lags) * grid[,.N]
```

```{r, include= FALSE, eval=FALSE, echo = FALSE}
# Train test:
train_test_split <- split_sample(dt_all)
train_data <- train_test_split$train_data
```

```{r,  include= FALSE, eval=FALSE, echo = FALSE}
grid_search <- rbindlist(
  lapply(
    1:length(lags),
    function(lag_idx) {
      
      p <- lags[lag_idx]
      
      message(sprintf("Running for lag=%i", p))
      
      # For given lag fit VAR:
      var_model <- vareg(train_data, lags = p) 
      y_true <- var_model$y_train
      
      # Test data:
      X_test <- prepare_test_data(train_test_split, lags=p)$X_test
      y_test <- prepare_test_data(train_test_split, lags=p)$y_test
      y_true_fcst <- y_test[1:n_ahead,]
      
      # Enter loop for Deep VAR:
      results <- rbindlist(
        lapply(
          1:nrow(grid),
          function(i) {
            
            list2env(c(grid[i,]), envir = environment()) # retrieve parameters
            
            pct_done <- ( ( (lag_idx-1)*grid[,.N] + i ) / n_sim ) * 100
            message(sprintf("Percent done: %0.2f", pct_done))
            
            # Fit Deep VAR model
            deepvar_model <- deepvareg(
              train_data, 
              lags=p, 
              num_units = unit,
              num_layers = layer,
              epochs=100,    
              p_drop_out = dropout
            )
            
            # Train RMSE
            train_rmse <- rbind(
              rmse(deepvar_model)[,model:="dvar"][,measure:="rmse"][,sample:="train"],
              rmse(var_model)[,model:="var"][,measure:="rmse"][,sample:="train"]
            )
            
            # Test RMSE
            test_rmse <- rbind(
              rmse(
                deepvar_model, X=X_test, y=y_test
              )[,model:="dvar"][,measure:="rmse"][,sample:="test"],
              rmse(
                var_model, X=X_test, y=y_test
              )[,model:="var"][,measure:="rmse"][,sample:="test"]
            )
            
            # Forecasts RMSE
            fcst_dvar <- forecast(deepvar_model, n.ahead = n_ahead)
            fcst_var <- forecast(var_model, n.ahead = n_ahead)
            fcst_rms <- rbind(
              rmsfe(
                fcst_dvar, y_true = y_true_fcst
              )[,model:="dvar"][,measure:="rmsfe"][,sample:="test"],
              rmsfe(
                fcst_var, y_true = y_true_fcst
              )[,model:="var"][,measure:="rmsfe"][,sample:="test"]
            )
            
            # Forecasts correlations:
            fcst_corr <- rbind(
              cor_fcst(
                fcst_dvar, y_true = y_true_fcst
              )[,model:="dvar"][,measure:="corr"][,sample:="test"],
              cor_fcst(
                fcst_var, y_true = y_true_fcst
              )[,model:="var"][,measure:="corr"][,sample:="test"]
            )
            
            # Put together:
            results <- rbind(
              train_rmse, 
              test_rmse, 
              fcst_rms, 
              fcst_corr
            )
            
            # Assign remaining variables:
            results[,lag:=p]
            results[,num_layer:=layer]
            results[,num_units:=unit]
            results[,dropout:=dropout]
            
            return(results)
          }
        )
      )
      
      return(results)
      
    }
  )
)
saveRDS(grid_search, "results/grid_search.rds")
```


