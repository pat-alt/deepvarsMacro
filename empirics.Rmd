# Empirical results 

```{r, echo = FALSE, warning=FALSE,message=FALSE}
rm(list = ls())
library(fbi)
library(deepvars)
library(data.table)
```

```{r, echo = FALSE, warning=FALSE,message=FALSE}
dt_all <- readRDS("data_VAR/preprocessed.rds")
var_cols <- colnames(dt_all)[2:ncol(dt_all)]
```

```{r}
# Choosing lags
lags <- lag_order(dt_all, max_lag = 12)$p
```

```{r, echo = FALSE, warning=FALSE,message=FALSE,eval=TRUE}
# VAR fitting
var_model <- vareg(dt_all, lags = lags)
saveRDS(var_model, file="results/var_model_full_sample.rds")
# Deep VAR fitting
deepvar_model <- deepvareg(dt_all, lags=lags, num_units = 100, epochs=100, p_drop_out = 0.5)
saveRDS(deepvar_model, file="results/deepvar_model_full_sample.rds")
```

```{r, eval=FALSE}
var_model <- readRDS("results/var_model_full_sample.rds")
deepvar_model <- readRDS("results/deepvar_model_full_sample.rds")
```


```{r}
# Cum RMSE plot
cum_loss_var <- cum_loss(var_model)$cum_loss[,type:="var"]
cum_loss_dvar <- cum_loss(deepvar_model)$cum_loss[,type:="deepvar"]
dt_plot <- rbind(cum_loss_dvar, cum_loss_var)
ggplot2::ggplot(data=dt_plot, ggplot2::aes(x=date, y=value, colour=type)) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~variable, scales = "free_y") +
  ggplot2::scale_color_discrete(name="Model:") +
  ggplot2::labs(
      x="Date",
      y="Squared error"
    )
```


In this section we present the main empirical results. First of all, we compare the in-sample fit of the VAR and the Deep-VAR. Then, we proceed with the out-of-sample predicitions. In both cases we compute the cumulative loss for the two methods. Finally, we use the fitted models to produce forecasts. 

In figure XX we can see the cumulative RMSE of both the VAR model and Deep-VAR model for each of the time series. The first thing we can observe is that the RMSE of the Deep-VAR is consistently flatter than the RMSE of the VAR. Indicating that the the performance of the Deep-VAR model is better than the one of the VAR throughout the time period of the experimental analysis. This simple fact implies that there are non linear relationships present in the time series. Another interesting insight we can derive form the figure is that the RMSE of the Deep-VAR ends up being even less than half of the RMSE of the VAR, clearly indicating that, overall, the Deep-VAR model outperforms the VAR model for the in-sample fit.

Figure XX is especially useful to asses in which specific periods the Deep-VAR model accomplishes much better fitting results than the VAR model. From the very beginning, we can observe that the slope of the VAR model is grater than the one of the Deep-VAR model, indicating that even in normal economic times, soft non linear relationships may be present in the series.

The first change we can observe is in the beginning of the 1980s. During the beginning of this decade, the RMSE of the Deep-VAR almost remains constant (it slope is close to zero), therefore, it almost makes no error. On the other hand, the RMSE of the VAR keeps increasing. For the case of the IP and the UR, the RMSE of the VAR  maintains its previous slope, meaning no improvement nor deterioration appears. Whereas for the CPI, it becomes approximately as twice as big, hence doubling its error, and for the FFR it is approximately quadrupled.

This can be explained by the early 1980s recession. This recession is considered to be the most sever since World War II. As figure XX shows, the Deep-VAR model almost perfectly fits the data in this period. This is due to the fact that economic recessions have a very high component of non linear relationships, therefore not only the Deep-VAR does better than the VAR, but it almost accomplishes a perfect fit. This idea is then reinforced by the poor performance of the VAR in this period for the CPI and FFR series. Both series, specially the FFR, are very volatile in this period. This means that non linear relationships are present and therefore, the Deep-VAR model remains unaffected by the volatility, while the VAR model struggles a lot to fit the data due to its limitations for fitting data generating processes with non linear components.

For the case of the 2007 recession we can see a pattern similar to the one for the recession of the early 1980: the Deep-VAR achieves a better fit because it can correctly identify the pattern soon enough. Furthermore, in the recovery time, the Deep-VAR cumulative RMSE still has a lower slope than the VAR cumulative RMSE. 

Finally, we can compare how both models perform in a period with highly non linear components, the Covid era. It can be clearly seen that, for both IP and UR, that is, the series that really changed its behavior with Covid, the VAR model struggles a lot to fit the data. For the VAR model, both series add in a few months approximately 50% of the error tehy had been accumulating for the previous 60 years. Whereas in the case of the Deep-VAR model, they only accumulate approximately 30% of the error they had been accumulating before. This, once again, reinforces our hypothesis that the Deep-VAR model structure helps dealing with non linarities on the data generating process and therefore fitting the data better on periods where non-linareities are present, which means that the Deep-VAR model can be extremely useful for recession periods.

## Train-test split

```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Train test split
train_test_split <- split_sample(dt_all)
train_data <- train_test_split$train_data
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Select the number of lags
lags <- lag_order(train_data)$p
```


```{r, echo = FALSE, warning=FALSE,message=FALSE, eval=TRUE}
# VAR
var_model <- vareg(train_data, lags = lags)
saveRDS(var_model, file="results/var_model_train.rds")
# Deep VAR
deepvar_model <- deepvareg(train_data, lags=lags, num_units = 100, epochs=100, p_drop_out = 0.5)
saveRDS(deepvar_model, file="results/deepvar_model_train.rds")
```


```{r, eval=FALSE}
var_model <- readRDS("results/var_model_train.rds")
deepvar_model <- readRDS("results/deepvar_model_train.rds")
```

```{r, echo = FALSE, warning=FALSE,message=FALSE}
y_true <- var_model$y_train
```

Now, we split the data into training data and test data. The model will be fitted in the training dataset and then we assess the performance of the model in the test dataset. This is done in order to see the performace of both models on data which is independent of the data that has been used to fit the model. The training dataset goes from March 1959 to November 2007, whereas the test data goes from December 2007 to March 2021, so we train the model on 80 percent of the data and we test the model on the remaining 20 percent. 

```{r, echo = FALSE, warning=FALSE,message=FALSE, results=FALSE, include = FALSE}
#VAR
pred_var <- predict(var_model)
plot(pred_var, y_true = y_true)
```

```{r, echo = FALSE, warning=FALSE,message=FALSE, results=FALSE, include = FALSE}
#DeepVAR
pred_deepvar <- predict(deepvar_model)
plot(pred_deepvar, y_true = y_true)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE,results=FALSE, include = FALSE}
#Predictions out of sample
X_test <- prepare_test_data(train_test_split, lags=lags)$X_test
y_test <- prepare_test_data(train_test_split, lags=lags)$y_test
```


```{r, echo = FALSE, warning=FALSE,message=FALSE,results=FALSE, include = FALSE}
#VAR
pred_var <- predict(var_model, X=X_test)
plot(pred_var, y_true = y_test)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE,results=FALSE, include = FALSE}
#DeepVAR
pred_dvar <- predict(deepvar_model, X=X_test)
plot(pred_dvar, y_true = y_test)
```


```{r, echo = FALSE, results = FALSE, warning=FALSE,message=FALSE, include = FALSE}
#RMSE 
rmse_var <- rbind(
  rmse(var_model)[,model:="var"][,sample:="train"],
  rmse(var_model, X=X_test, y=y_test)[,model:="var"][,sample:="test"]
)
rmse_dvar <- rbind(
  rmse(deepvar_model)[,model:="deepvar"][,sample:="train"],
  rmse(deepvar_model, X=X_test, y=y_test)[,model:="deepvar"][,sample:="test"]
)
tab_rmse <- rbind(rmse_var, rmse_dvar)
tab_rmse <- data.table::dcast(tab_rmse, sample + variable ~ model, value.var = "value")
tab_rmse[, ratio:= deepvar/var]
knitr::kable(tab_rmse, 
  col.names = c("Sample", "Variable", "DVAR", "VAR", "Ratio"),
  digits = 5) 
```

The following table shows ths Root Mean Squared Error (RMSE) for the in-sample and the out-of-sample predictions of both the VAR model and the Deep-VAR model. We can see that the RMSE for the Deep VAR outperforms the one for the classic VAR for both the training data and the test data and for all time series. The fifth column of the table shows us the ratio between the Deep-VAR and the VAR. The lower the ratio, the better the Deep-VAR with respect to the VAR. Note that for the industrial production and for the unemployment rate the Deep-VAR does fairly well compared to the VAR.

```{r, echo = FALSE, results='asis', warning=FALSE,message=FALSE}
library(xtable)
dtf<- xtable(tab_rmse[, -"Mean"], caption = c("RMS"))
names(dtf) <- c('Sample','Variable', 'DeepVAR', "VAR", "Ratio")
bold <- function(x){
paste('{\\textbf{',x,'}}', sep ='')
}
italic <- function(x){
paste0('{\\emph{ ', x, '}}')
}
print(dtf, sanitize.colnames.function = bold, sanitize.rownames.function = italic, booktabs = TRUE, include.rownames=FALSE)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Cumulative loss in-sample

cum_loss_var <- cum_loss(var_model)$cum_loss[,type:="var"]
cum_loss_dvar <- cum_loss(deepvar_model)$cum_loss[,type:="deepvar"]
dt_plot <- rbind(cum_loss_dvar, cum_loss_var)
ggplot2::ggplot(data=dt_plot, ggplot2::aes(x=date, y=value, colour=type)) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~variable, scales = "free_y") +
  ggplot2::scale_color_discrete(name="Model:") +
  ggplot2::labs(
      x="Date",
      y="Squared error"
    )
```



```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Cumulative loss out-of-sample
cum_loss_var <- cum_loss(var_model)$cum_loss[,type:="var"]
cum_loss_dvar <- cum_loss(deepvar_model)$cum_loss[,type:="deepvar"]
dt_plot <- rbind(cum_loss_dvar, cum_loss_var)
ggplot2::ggplot(data=dt_plot, ggplot2::aes(x=date, y=value, colour=type)) +
  ggplot2::geom_line() +
  ggplot2::facet_wrap(~variable, scales = "free_y") +
  ggplot2::scale_color_discrete(name="Model:") +
  ggplot2::labs(
      x="Date",
      y="Squared error"
    )
```

```{r}
n_ahead <- 12
y_true <- y_test[1:n_ahead,]
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#Forecasts
#VAR
fcst_var <- forecast(var_model, n.ahead = n_ahead)
plot(fcst_var, y_true=y_true, history = 20)
```


```{r, echo = FALSE, warning=FALSE,message=FALSE}
#DeepVAR
fcst_dvar <- forecast(deepvar_model, n.ahead = n_ahead)
plot(fcst_dvar, y_true=y_true, history = 20)
```

```{r}
rmsfe(fcst_dvar, y_true = y_true)
rmsfe(fcst_var, y_true = y_true)
```



```{r, echo = FALSE, warning=FALSE,message=FALSE}

#DIEBOLD AND MARIANO
library(multDM)
tab_dm <- data.table("ID" = var_cols)
tab_dm[, DM:= lapply(ID, function(x) DM.test(fcst_dvar$fcst[, get(x)], fcst_var$fcst[, get(x)], H1="less", h=1, y=y_true)$p.value)]
knitr::kable(tab_dm,
  col.names = c("Varaible", "DM p-value"),
  digits = 5)
```



