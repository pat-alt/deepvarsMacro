---
title: "Neural additive VAR"
subtitle: "Proposal"
author:
- "Marc AgustÃ­ (marc.agusti@barcelonagse.eu)"
- "Patrick Altmeyer (patrick.altmeyer@barcelonagse.eu)"
- "Ignacio Vidal-Quadras Costa (ignacio.vidalquadrascosta@barcelonagse.eu)"
date: "`r format(Sys.Date(), '%B, %Y')`"
output: 
  bookdown::html_document2: default
  bookdown::pdf_document2: 
    toc: false
bibliography: "bib.bib"
link-citations: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Loading and merging data

Below I just load and merge the data for the US given the .csv files you moved in the `data_VAR` folder. 

> NOTE: Eventually we want to merge date for other countries in here as well to have one clean data frame in long (tidy) format to work with.
--- Pat

```{r}
library(data.table)
data_files <- list.files("data_VAR")
countries <- c("US", "UK") # add more as more data available
dt <- rbindlist(
  lapply(
    countries,
    function(country) {
      data_files_country <- data_files[grepl(country,data_files,ignore.case = TRUE)] # country-level data
      rbindlist(
        lapply(
          data_files_country,
          function(file_path) {
            print(file_path)
            dt <- fread(file.path("data_VAR", file_path))
            setnames(dt, colnames(dt), c("date", "value"))
            variable <- file_path
            for (pattern in c("UK", "US",".csv","_")) {
              variable <- stringr::str_remove(variable, pattern) # remove all patterns except variable
            }
            dt[,variable:=variable]
            dt[,country:=toupper(country)]
            return(dt)
          }
        )
      )
    }
  )
)
dt[,date:=as.Date(date)]

us_dt <- dt[dt$country == "US",]
uk_dt <- dt[dt$country == "UK",]
```

# Exploring

Now let's have a quick look at the data. First of all we note that the date range is slightly different, but that is not a reason for concern.

```{r}
dt[,.(date_range=range(date)),by=.(variable,country)]
```

Let's also quickly inspect the time series visually. Unsurprisingly, lots of things we want to take into account here: non-stationarity, business cycles and trends. `CPI` we probably want to convert into inflation before it enters the VAR. 

```{r}
library(ggplot2)
ggplot2::ggplot(dt) +
  ggplot2::geom_line(ggplot2::aes(y=value, x=date)) +
  ggplot2::facet_wrap(country ~ variable, scales = "free_y") +
  ggplot2::theme_bw() +
  ggplot2::labs(
    x="Date",
    y="Value"
  )
```

Let's save a copy of that raw data to disk should we ever want to transform in different ways for different approaches.

```{r, eval=FALSE}
saveRDS(dt, "data_VAR/merged_raw.rds")
```

# Transforming

## VAR

```{r}
dt <- readRDS("data_VAR/merged_raw.rds") # load the raw merged data
```

Can formalize this through ADF tests, conintegration (VECM?), ... in case supervisor wants to see that, but for the simple VAR we may just get rid of the obvious non-stationarity. 

> Is CPI correctly defined here? Do we want first differences of CPI or implied inflation rate?
> Similarly shouldn't we use differences in log of GDP (more of a growth/pct rate measure)? Same for unemployment?

```{r}
dt[,value:=c(NA,diff(value)),by=.(variable,country)]
dt <- na.omit(dt)
```

Looking at this data again, things already look much better in first differences. The `CPI` still exerts some trending behaviour and may need some work. Structural break due to COVID needs to be taking into account in final analysis.

> Consideration: for the NAVAR, should the data be standardizes?
--- Pat

```{r}
library(ggplot2)
ggplot2::ggplot(dt) +
  ggplot2::geom_line(ggplot2::aes(y=value, x=date)) +
  ggplot2::facet_wrap(variable ~ country, scales = "free_y") +
  ggplot2::theme_bw() +
  ggplot2::labs(
    x="Date",
    y="Value"
  )
```

Finally, let's turn the data into a wide format to be fed to then later estimate the VAR. Let's also make sure we cover the exact same time frame for all series. We do so by first completing the time data frame with respect to the `date` variable. Then we cast the data across `variable`.

```{r}
library(tidyr)
dt <- data.table(tidyr::complete(dt, date, nesting(variable, country))) # complete data frame wrt date
dt <- dcast(dt, date + country ~ variable, value.var = "value") # cast data
dt
```

Now, when we omit `NA` we will automatically get rid of all rows that contain a missing values for at least one of the time series. Just in case we want to add further visualizations of the preprocessed data we will also save a version of the data in long (tidy) format. Both versions are then saved to disk.

```{r, eval=FALSE}
dt <- na.omit(dt)
dt_l <- melt(dt, id.vars = c("date", "country"))
saveRDS(dt, "data_VAR/preprocessed.rds")
saveRDS(dt_l, "data_VAR/preprocessed_tidy.rds")
```



