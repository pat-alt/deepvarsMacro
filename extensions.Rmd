---
output:
  pdf_document: default
  html_document: default
---
# Caveats and extensions

In this section we will talk about the main short-falls of our work, and potentital ways to improve it.

In this paper we have developed a method to produce point forecasts which has shown to overperform the traditional VAR. However, policy makers do not only take decisions based on point estimates, but they also take into account how uncertain they are. That is why, when constructing forecats you also want to infer confidence intervals for your point estimates. Doing that with the VAR methodology is not difficult, given that standard errors are inherent to the model, and easily attainable. This is not the case for the Deep VAR, but this does not mean that we cannot obtain them but that we need to rely on bootstraping or montecarlo techniques to infer these bounds. This relates to the dropout rate used when fitting the Deep VAR in the test set. Given that the dropout rate specifies the number of observations that the model randomly removes at each layer, each time the model is refitted the test set will result in differnt but similar predictions. Threby, this can be used to get the standard errors needed for reporting the confidence intervals. This approach of refitting the model in the test set can be used for getting convidence intervals for the predictions of the test set. 


Impulse response functions are another missing milestone in our paper and to which future research should be dedicated. IRFs are important to see how your model captures the dynamics of the variables in response to a shock in a given period of time. When estimating the model with the traditional VAR, computing IRFs is quite straighforward. Provided that all the roots of the autoregressive polynomial lie outside the unit circle, transforming the model into its moving average representation and plugging the shock into the vector moving average (VMA) representaion resutls into the IRF of the shock analysed. However, generating the IRFs is more difficult in the Deep VAR setting given that we cannot get the Deep VMA representation as a consequence of its underlying structure. Thereby, future work would be needed in this direction to be able to derive the IRFs from the Deep VAR model. 

Within the VAR framework, it is quite usual to obtain the Forecast Error Variance Decomposition (FEVD) as well. This allows the researcher or the policy maker to exactly know what percentage of the variability of the forecast error of one variable is explained by the other variables in the system. However, is not clear how to get that from the Deep VAR perspective. Our intuition is that, in the same way you can use montecarlo simulations to get different estimations through the dropput rate and therefore get some variability to infer the standard error, you could also construct different forecasts. These forecasts would lead to different forecast errors and threfore potentially ending up reproducing the FEDV for the Deep VAR.

Apart from the forecasts and the previouly mentioned important insights that can be derived from the VAR model and that could potentially be derived from the Deep VAR model with further work, poilcy makers are also concerned about the interpretabily of the model. The linear relationship of inputs and outputs of the VAR allows the researcher or policy maker to asses the effect of one variable of the system to another and threfore assessing if that variable granger causes the other. In the case of the Deep VAR model, its non linar structure makes it impossible to recover this assiciatinos. There has been some research already devoted to this area. For instance the Neural Aditive Vector Autorregression (NAVAR) aims to combine neural networks in the first stage of the model use a linear additive structure in the end in order to assess if one varible granger causes another. It uses a NN for each variable in the system to output the degree of causality of this variable to all the variables in the system in the form of contributions. Then, once the model has assessed the contribution of all the variables to themself and the others, an additive structure is implemented to assess the contributions of the system to each of the variables.




